name: ezOverThinking CI/CD

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  # Code Quality and Linting
  code-quality:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black ruff mypy pre-commit
          pip install -r requirements.txt

      - name: Run Black formatter check
        run: black --check .

      - name: Run Ruff linter
        run: ruff check .

      - name: Run MyPy type checker
        run: mypy src/ api/ --ignore-missing-imports

      - name: Run pre-commit hooks
        run: pre-commit run --all-files

  # Security Scanning
  security:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install safety bandit
          pip install -r requirements.txt

      - name: Run Safety check for known vulnerabilities
        run: safety check

      - name: Run Bandit security linter
        run: bandit -r src/ api/ -f json -o bandit-report.json

      - name: Upload Bandit report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: bandit-report
          path: bandit-report.json

  # Dependency Scanning
  dependency-check:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Build and Test
  build-and-test:
    runs-on: ubuntu-latest

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: ezoverthinking_test
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create test environment file
        run: |
          cat > .env << EOF
          OPENAI_API_KEY=test_key
          ANTHROPIC_API_KEY=test_key
          LANGCHAIN_API_KEY=test_key
          DATABASE_URL=postgresql://testuser:testpass@localhost:5432/ezoverthinking_test
          REDIS_URL=redis://localhost:6379/0
          ENVIRONMENT=test
          DEBUG=False
          SECRET_KEY=test_secret_key
          EOF

      - name: Wait for services
        run: |
          sleep 10
          python -c "import redis; r = redis.Redis(host='localhost', port=6379); r.ping()"
          python -c "import psycopg2; conn = psycopg2.connect(host='localhost', port=5432, user='testuser', password='testpass', database='ezoverthinking_test'); conn.close()"

      - name: Run basic import tests
        run: |
          python -c "from src.agents.base_agent import BaseAgent; print('✅ Base agent imports successfully')"
          python -c "from src.models.schemas import UserConcern, AgentResponse; print('✅ Models import successfully')"
          python -c "from api.main import app; print('✅ API imports successfully')" || echo "⚠️ API not ready yet"

      - name: Test agent creation
        run: |
          python -c "
          from src.agents.base_agent import AgentType, AgentFactory
          from src.models.schemas import UserConcern, AnxietyLevel

          # Test agent factory
          print('Testing agent factory...')

          # This will be available after Week 2 implementation
          # agent = AgentFactory.create_agent(AgentType.INTAKE_SPECIALIST)
          # print(f'✅ Created agent: {agent.name}')

          # Test data models
          concern = UserConcern(
              original_worry='Test worry',
              user_id='test_user',
              anxiety_level=AnxietyLevel.MINIMAL
          )
          print(f'✅ Created user concern: {concern.original_worry}')
          "

  # Docker Build
  docker-build:
    runs-on: ubuntu-latest
    needs: [code-quality, security, build-and-test]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create Dockerfile
        run: |
          cat > Dockerfile << 'EOF'
          FROM python:3.11-slim

          WORKDIR /app

          # Install system dependencies
          RUN apt-get update && apt-get install -y \
              build-essential \
              curl \
              && rm -rf /var/lib/apt/lists/*

          # Copy requirements and install Python dependencies
          COPY requirements.txt .
          RUN pip install --no-cache-dir -r requirements.txt

          # Copy application code
          COPY . .

          # Create non-root user
          RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
          USER appuser

          # Expose port
          EXPOSE 8000

          # Health check
          HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
              CMD curl -f http://localhost:8000/health || exit 1

          # Run application
          CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
          EOF

      - name: Build Docker image
        run: |
          docker build -t ezoverthinking:test .
          docker images

      - name: Test Docker image
        run: |
          # Test that image runs without errors
          docker run --rm -d --name test-container ezoverthinking:test sleep 30
          docker ps
          docker logs test-container
          docker stop test-container

  # Performance Testing
  performance-test:
    runs-on: ubuntu-latest
    needs: [build-and-test]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install performance testing tools
        run: |
          pip install locust pytest-benchmark

      - name: Create basic performance test
        run: |
          cat > performance_test.py << 'EOF'
          import time
          import asyncio
          from src.models.schemas import UserConcern, AnxietyLevel

          def test_model_creation_performance():
              """Test performance of model creation"""
              start_time = time.time()
              
              for i in range(1000):
                  concern = UserConcern(
                      original_worry=f"Test worry {i}",
                      user_id=f"user_{i}",
                      anxiety_level=AnxietyLevel.MINIMAL
                  )
              
              end_time = time.time()
              duration = end_time - start_time
              
              print(f"Created 1000 UserConcern objects in {duration:.3f} seconds")
              print(f"Average: {duration/1000*1000:.3f} ms per object")
              
              # Assert reasonable performance
              assert duration < 1.0, f"Model creation too slow: {duration:.3f}s"

          if __name__ == "__main__":
              test_model_creation_performance()
              print("✅ Performance tests passed")
          EOF

      - name: Run performance tests
        run: python performance_test.py

  # Documentation Check
  documentation:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Check README exists
        run: |
          if [ -f "README.md" ]; then
            echo "✅ README.md exists"
            wc -l README.md
          else
            echo "❌ README.md missing"
            exit 1
          fi

      - name: Check documentation structure
        run: |
          required_files=("README.md" "requirements.txt" "pyproject.toml" ".env.example")
          for file in "${required_files[@]}"; do
            if [ -f "$file" ]; then
              echo "✅ $file exists"
            else
              echo "❌ $file missing"
              exit 1
            fi
          done

      - name: Validate project structure
        run: |
          required_dirs=("src" "api" "frontend" "docs")
          for dir in "${required_dirs[@]}"; do
            if [ -d "$dir" ]; then
              echo "✅ $dir/ directory exists"
            else
              echo "❌ $dir/ directory missing"
              exit 1
            fi
          done

  # Deployment Preparation
  deployment-prep:
    runs-on: ubuntu-latest
    needs: [code-quality, security, build-and-test, docker-build]
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Create deployment artifacts
        run: |
          mkdir -p deployment

          # Create deployment configuration
          cat > deployment/docker-compose.prod.yml << 'EOF'
          version: '3.8'

          services:
            app:
              build: .
              ports:
                - "8000:8000"
              environment:
                - ENVIRONMENT=production
                - DATABASE_URL=${DATABASE_URL}
                - REDIS_URL=${REDIS_URL}
                - OPENAI_API_KEY=${OPENAI_API_KEY}
                - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
              depends_on:
                - redis
                - postgres
              restart: unless-stopped

            redis:
              image: redis:7-alpine
              volumes:
                - redis_data:/data
              restart: unless-stopped

            postgres:
              image: postgres:15-alpine
              environment:
                POSTGRES_DB: ezoverthinking
                POSTGRES_USER: ${POSTGRES_USER}
                POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
              volumes:
                - postgres_data:/var/lib/postgresql/data
              restart: unless-stopped

          volumes:
            redis_data:
            postgres_data:
          EOF

          # Create deployment script
          cat > deployment/deploy.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "🚀 Deploying ezOverThinking to production..."

          # Pull latest code
          git pull origin main

          # Build and start services
          docker-compose -f docker-compose.prod.yml build
          docker-compose -f docker-compose.prod.yml up -d

          # Wait for services to be ready
          echo "⏳ Waiting for services..."
          sleep 30

          # Health check
          curl -f http://localhost:8000/health || exit 1

          echo "✅ Deployment completed successfully!"
          EOF

          chmod +x deployment/deploy.sh

      - name: Upload deployment artifacts
        uses: actions/upload-artifact@v3
        with:
          name: deployment-artifacts
          path: deployment/

  # Summary Report
  summary:
    runs-on: ubuntu-latest
    needs:
      [
        code-quality,
        security,
        build-and-test,
        docker-build,
        performance-test,
        documentation
      ]
    if: always()

    steps:
      - name: Create summary report
        run: |
          echo "# ezOverThinking CI/CD Summary" > summary.md
          echo "" >> summary.md
          echo "## Build Results" >> summary.md
          echo "- Code Quality: ${{ needs.code-quality.result }}" >> summary.md
          echo "- Security: ${{ needs.security.result }}" >> summary.md
          echo "- Build & Test: ${{ needs.build-and-test.result }}" >> summary.md
          echo "- Docker Build: ${{ needs.docker-build.result }}" >> summary.md
          echo "- Performance: ${{ needs.performance-test.result }}" >> summary.md
          echo "- Documentation: ${{ needs.documentation.result }}" >> summary.md
          echo "" >> summary.md
          echo "## Next Steps" >> summary.md
          echo "1. Review any failed checks above" >> summary.md
          echo "2. Continue with Week 2 implementation" >> summary.md
          echo "3. Implement individual agent classes" >> summary.md
          echo "" >> summary.md
          echo "Generated on: $(date)" >> summary.md

          cat summary.md

      - name: Upload summary
        uses: actions/upload-artifact@v3
        with:
          name: ci-summary
          path: summary.md

  # Workflow dispatch for manual runs
  manual-run:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'

    steps:
      - uses: actions/checkout@v4

      - name: Manual workflow info
        run: |
          echo "🔧 Manual workflow triggered"
          echo "Branch: ${{ github.ref }}"
          echo "Commit: ${{ github.sha }}"
          echo "Actor: ${{ github.actor }}"
